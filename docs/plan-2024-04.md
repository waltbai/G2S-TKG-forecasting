
## Plan
- [ ] Small-scale Preliminary Experiments on GPT2
  - [x] Preprocess
    - [x] TKG data loader
  - [x] Quadruple Prompt
    - [x] Quadruple-style Prompt
      - [x] Time anonymize
      - [x] Entity and Relation anonymize
      - [x] Unit test
  - [ ] Model
    - [x] In-Context Learning Model (2024.4.8~2024.4.14)
      - [x] Tokenization and indexing
      - [x] Predict: memory limit, do not use batching
      - [x] Evaluate
    - [x] Fine-Tuning Model
      - [x] Train
      - [ ] Checkpoint
  - [x] Metric
    - [x] Raw Hit@k
    - [x] Time-Filter Hit@k

## Anonymous Pretrain and Entity Assignment
### Pretrain
Learn variables and computations
[ENT_0, REL_0, ENT_1, xxx]  
...

### Fine-tune
Baseline:  
[China, agreement, Russia, xxx]  
[xxx]  
Russia 

Assignment:  
Map: ENT_0: China, ENT_1: Russia  
[ENT_0, REL_0, ENT_1, xxx]  
ENT_1 -> Russia  

[ENT_0: China, REL_0: make agreement, ENT_1: Russia, xxx]
